{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afbe0572",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "This notebook attempts to achieve a high accuracy of ReCOGS via instructions on how to chunk a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6dd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "def variable_change(phi, sourcevar, targetvar, flag=\"000000\"):\n",
    "    replace_re = re.compile(rf\"\\b{sourcevar}\\b\")\n",
    "    return replace_re.sub(f\"{flag}{targetvar}\", phi)\n",
    "\n",
    "\n",
    "def recogs_exact_match(gold, pred, flag=\"000000\"):\n",
    "\n",
    "    flag = \"000000\"\n",
    "    if not isinstance(gold, str):\n",
    "        gold = normalize_formula(gold.logical_form)\n",
    "        pred = normalize_formula(pred.logical_form)\n",
    "    \n",
    "\n",
    "    gold_conj_set = get_conj_set(gold)\n",
    "    # Loop over all viable mappings from pred_vars to gold_vars:\n",
    "    for this_map in _candidate_variable_maps(gold, pred):\n",
    "        phi = pred\n",
    "        # For each mapping, we need to replace the variables in        \n",
    "        for sourcevar, targetvar in this_map.items():\n",
    "            # The flag makes sure we don't accidentally do a chain\n",
    "            # of replacements via successive changes in situations\n",
    "            # where the domain and range of `this_map` share vars.\n",
    "            phi = variable_change(phi, sourcevar, targetvar, flag=flag)\n",
    "        phi = phi.replace(flag, \"\")\n",
    "        phi_conj_set = get_conj_set(phi)\n",
    "        # This step assumes that we have no conjuncts that are\n",
    "        # tautologies, contradictions, or equality predications. If\n",
    "        # such are introduced, they need to be identified ahead of\n",
    "        # time and treated separately -- tautologies would be removed,\n",
    "        # contradictions would reduce to comparisons of only those\n",
    "        # conjuncts, and equality statements would call for special\n",
    "        # handling related to variables mapping.\n",
    "        if phi_conj_set == gold_conj_set:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def normalize_formula(phi):\n",
    "    return phi.replace(\" \", \"\").replace(\"AND\" , \" AND \")\n",
    "\n",
    "\n",
    "binary_pred_re = re.compile(r\"\"\"\n",
    "    (\\w+)\n",
    "    \\s*\n",
    "    \\(\n",
    "    \\s*\n",
    "    (\\d+)\n",
    "    \\s*\n",
    "    ,\n",
    "    \\s*\n",
    "    (\\d+)\n",
    "    \\s*\n",
    "    \\)\"\"\", re.VERBOSE)\n",
    "\n",
    "\n",
    "unary_pred_re = re.compile(r\"\"\"\n",
    "    (\\w+)\n",
    "    \\s*\n",
    "    \\(\n",
    "    \\s*\n",
    "    (\\d+)\n",
    "    \\s*\n",
    "    \\)\"\"\", re.VERBOSE)\n",
    "\n",
    "\n",
    "def _candidate_variable_maps(gold, pred):\n",
    "    # This creates a mapping from tuples of predicates into their\n",
    "    # associated variables. These serve as equivalence classes over\n",
    "    # variables that could possibly be translations of each other.\n",
    "    gold_map = _map_get_preds_to_vars(gold)\n",
    "    pred_map = _map_get_preds_to_vars(pred)\n",
    "\n",
    "    # For each prediction variable, get the set of potential\n",
    "    # translations for it:\n",
    "    pred2gold = defaultdict(list)\n",
    "    for preds, pvars in pred_map.items():\n",
    "        gvars = gold_map[preds]\n",
    "        for pvar in pvars:\n",
    "            pred2gold[pvar] = gold_map[preds]\n",
    "\n",
    "    # Variable sets:\n",
    "    gold_vars = set(get_variables(gold))\n",
    "    pred_vars = set(get_variables(pred))\n",
    "\n",
    "    # Now generate potentially viable mappings:\n",
    "    for vals in list(product(*list(pred2gold.values()))):\n",
    "        d = dict(zip(pred2gold.keys(), vals))\n",
    "        if set(d.keys()) == pred_vars and set(d.values()) == gold_vars:\n",
    "            yield d\n",
    "\n",
    "\n",
    "def _map_get_preds_to_vars(phi):\n",
    "    var2pred = defaultdict(list)\n",
    "    for pred, var in unary_pred_re.findall(phi):\n",
    "        var2pred[var].append(pred)\n",
    "    # We could do somewhat less search by specializing to first and\n",
    "    # second position for these predicates, but I think it's fine\n",
    "    # as-is.\n",
    "    for pred, var1, var2 in binary_pred_re.findall(phi):\n",
    "        var2pred[var1].append(pred)\n",
    "        var2pred[var2].append(pred)\n",
    "    pred2var = defaultdict(list)\n",
    "    for var, preds in var2pred.items():\n",
    "        pred2var[tuple(sorted(preds))].append(var)\n",
    "    return pred2var\n",
    "\n",
    "\n",
    "def get_variables(phi):\n",
    "    variable_re = re.compile(r\"(\\d+)\")\n",
    "    return variable_re.findall(phi)\n",
    "\n",
    "\n",
    "def get_conj_set(phi):\n",
    "    conj_splitter_re  = re.compile(r\"\\s*(?:AND|;)\\s*\")\n",
    "    return set(conj_splitter_re.split(phi))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "21f6d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "SRC_DIRNAME = \"data\"\n",
    "\n",
    "def load_split(filename):\n",
    "    return pd.read_csv(\n",
    "        filename,\n",
    "        delimiter=\"\\t\",\n",
    "        names=['input', 'output', 'category'])\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for splitname in (\"RECOGStrain\", \"RECOGSdev\", \"RECOGSgen\"):\n",
    "    dataset[splitname] = load_split(f\"{SRC_DIRNAME}/{splitname}.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "89007c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe thought that a hippo cleaned .\n",
      "Zoe ( 10 ) ; hippo ( 36 ) ; think ( 3 ) AND agent ( 3 , 10 ) AND ccomp ( 3 , 44 ) AND clean ( 44 ) AND agent ( 44 , 36 )\n"
     ]
    }
   ],
   "source": [
    "test_sentence = dataset[\"RECOGSgen\"][\"input\"].tolist()[1]\n",
    "print (test_sentence)\n",
    "\n",
    "gold_Label = dataset[\"RECOGSgen\"][\"output\"].tolist()[1]\n",
    "print (gold_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bf28d2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 446  (0.0):   2%|‚ñè         | 446/24155 [01:16<1:07:27,  5.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "dspy_recogs_train = [\n",
    "    dspy.Example(\n",
    "        sentence=row['input'], logical_form=row['output']\n",
    "    ).with_inputs(\"sentence\")\n",
    "    for _, row in dataset['RECOGStrain'].iterrows()]\n",
    "\n",
    "dspy_recogs_dev = [\n",
    "    dspy.Example(\n",
    "        sentence=row['input'], logical_form=row['output']\n",
    "    ).with_inputs(\"sentence\")\n",
    "    for _, row in dataset['RECOGSdev'].iterrows()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "75597f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import openai\n",
    "import os\n",
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "import spacy\n",
    "\n",
    "root_path = '.'\n",
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(root_path, 'cache')\n",
    "# keep the API keys in a `.env` file in the local root directory\n",
    "load_dotenv()\n",
    "openai_key = os.getenv('OPENAI_API_KEY')  # use the .env file as it is a good practice to keep keys outside of one's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "29d132a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.OpenAI(model='gpt-3.5-turbo', api_key=openai_key)\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "50c43b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchyParse(dspy.Signature):\n",
    "    __doc__ = \"\"\"Parse a sentence into a hierarchy of phrases.\"\"\"\n",
    "    sentence = dspy.InputField(desc=\"a sentence to parse\")\n",
    "    hierarchy = dspy.OutputField(desc=\"propose a hierarchy of phrases in the sentence; the hierarchy is marked by opening and closing brackets for each chunk and can be nested; the output should be a string\")\n",
    "\n",
    "class ReCOGS(dspy.Signature):\n",
    "    __doc__ = \"\"\"Given a sentence hierarchy, convert it to a ReCOGS logical form\"\"\"\n",
    "    hierarchy = dspy.InputField(desc=\"a hierarchy of phrases in the sentence\")\n",
    "    logical_form = dspy.OutputField(desc=\"the ReCOGS logical form of the sentence hierarchy. the output should be a string\")\n",
    "\n",
    "class BasicParse(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.parse = dspy.Predict(HierarchyParse)\n",
    "        self.generaterecogs = dspy.Predict(ReCOGS)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        hierarchy = self.parse(sentence=sentence).hierarchy\n",
    "        return self.generaterecogs(hierarchy=hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4569960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "def variable_change(phi, sourcevar, targetvar, flag=\"000000\"):\n",
    "    replace_re = re.compile(rf\"\\b{sourcevar}\\b\")\n",
    "    return replace_re.sub(f\"{flag}{targetvar}\", phi)\n",
    "\n",
    "\n",
    "def recogs_exact_match(gold, pred, flag=\"000000\"):\n",
    "\n",
    "    flag = \"000000\"\n",
    "    if not isinstance(gold, str):\n",
    "        gold = normalize_formula(gold.logical_form)\n",
    "        pred = normalize_formula(pred.logical_form)\n",
    "    \n",
    "\n",
    "    gold_conj_set = get_conj_set(gold)\n",
    "    # Loop over all viable mappings from pred_vars to gold_vars:\n",
    "    for this_map in _candidate_variable_maps(gold, pred):\n",
    "        phi = pred\n",
    "        # For each mapping, we need to replace the variables in        \n",
    "        for sourcevar, targetvar in this_map.items():\n",
    "            # The flag makes sure we don't accidentally do a chain\n",
    "            # of replacements via successive changes in situations\n",
    "            # where the domain and range of `this_map` share vars.\n",
    "            phi = variable_change(phi, sourcevar, targetvar, flag=flag)\n",
    "        phi = phi.replace(flag, \"\")\n",
    "        phi_conj_set = get_conj_set(phi)\n",
    "        # This step assumes that we have no conjuncts that are\n",
    "        # tautologies, contradictions, or equality predications. If\n",
    "        # such are introduced, they need to be identified ahead of\n",
    "        # time and treated separately -- tautologies would be removed,\n",
    "        # contradictions would reduce to comparisons of only those\n",
    "        # conjuncts, and equality statements would call for special\n",
    "        # handling related to variables mapping.\n",
    "        if phi_conj_set == gold_conj_set:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def normalize_formula(phi):\n",
    "    return phi.replace(\" \", \"\").replace(\"AND\" , \" AND \")\n",
    "\n",
    "\n",
    "binary_pred_re = re.compile(r\"\"\"\n",
    "    (\\w+)\n",
    "    \\s*\n",
    "    \\(\n",
    "    \\s*\n",
    "    (\\d+)\n",
    "    \\s*\n",
    "    ,\n",
    "    \\s*\n",
    "    (\\d+)\n",
    "    \\s*\n",
    "    \\)\"\"\", re.VERBOSE)\n",
    "\n",
    "\n",
    "unary_pred_re = re.compile(r\"\"\"\n",
    "    (\\w+)\n",
    "    \\s*\n",
    "    \\(\n",
    "    \\s*\n",
    "    (\\d+)\n",
    "    \\s*\n",
    "    \\)\"\"\", re.VERBOSE)\n",
    "\n",
    "\n",
    "def _candidate_variable_maps(gold, pred):\n",
    "    # This creates a mapping from tuples of predicates into their\n",
    "    # associated variables. These serve as equivalence classes over\n",
    "    # variables that could possibly be translations of each other.\n",
    "    gold_map = _map_get_preds_to_vars(gold)\n",
    "    pred_map = _map_get_preds_to_vars(pred)\n",
    "\n",
    "    # For each prediction variable, get the set of potential\n",
    "    # translations for it:\n",
    "    pred2gold = defaultdict(list)\n",
    "    for preds, pvars in pred_map.items():\n",
    "        gvars = gold_map[preds]\n",
    "        for pvar in pvars:\n",
    "            pred2gold[pvar] = gold_map[preds]\n",
    "\n",
    "    # Variable sets:\n",
    "    gold_vars = set(get_variables(gold))\n",
    "    pred_vars = set(get_variables(pred))\n",
    "\n",
    "    # Now generate potentially viable mappings:\n",
    "    for vals in list(product(*list(pred2gold.values()))):\n",
    "        d = dict(zip(pred2gold.keys(), vals))\n",
    "        if set(d.keys()) == pred_vars and set(d.values()) == gold_vars:\n",
    "            yield d\n",
    "\n",
    "\n",
    "def _map_get_preds_to_vars(phi):\n",
    "    var2pred = defaultdict(list)\n",
    "    for pred, var in unary_pred_re.findall(phi):\n",
    "        var2pred[var].append(pred)\n",
    "    # We could do somewhat less search by specializing to first and\n",
    "    # second position for these predicates, but I think it's fine\n",
    "    # as-is.\n",
    "    for pred, var1, var2 in binary_pred_re.findall(phi):\n",
    "        var2pred[var1].append(pred)\n",
    "        var2pred[var2].append(pred)\n",
    "    pred2var = defaultdict(list)\n",
    "    for var, preds in var2pred.items():\n",
    "        pred2var[tuple(sorted(preds))].append(var)\n",
    "    return pred2var\n",
    "\n",
    "\n",
    "def get_variables(phi):\n",
    "    variable_re = re.compile(r\"(\\d+)\")\n",
    "    return variable_re.findall(phi)\n",
    "\n",
    "\n",
    "def get_conj_set(phi):\n",
    "    conj_splitter_re  = re.compile(r\"\\s*(?:AND|;)\\s*\")\n",
    "    return set(conj_splitter_re.split(phi))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b263f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624c40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d73695d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/24155 [00:00<00:15, 1562.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 14 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot, LabeledFewShot, BootstrapFewShotWithRandomSearch\n",
    "\n",
    "fewshot_optimizer = BootstrapFewShot(metric=recogs_exact_match)\n",
    "compiled = fewshot_optimizer.compile(student = BasicParse(), trainset=dspy_recogs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "05150524",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssamp = dataset['RECOGSgen'].sample(25)\n",
    "ssamp['prediction'] = ssamp.input.apply(\n",
    "    lambda x: compiled(sentence=x).logical_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e24bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e553d722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ssamp['correct'] = ssamp.apply(\n",
    "    lambda row: recogs_exact_match(row['output'], row['prediction']), axis=1)  \n",
    "ssamp['correct'].sum() / ssamp.shape[0]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8bcd7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Step 1: Define a signature\n",
    "class SemanticParsingSignature(dspy.Signature):\n",
    "    \"\"\"Map a sentence to a structured logical form.\"\"\"\n",
    "    sentence = dspy.InputField()\n",
    "    logical_form = dspy.OutputField()\n",
    "\n",
    "# Step 2: Create few-shot examples from the study examples\n",
    "fewshot_examples = [\n",
    "    dspy.Example(sentence=\"A worm held Luna .\",\n",
    "                 logical_form=\"TOWEL ( X _ 1 ) AND HOLD &. AGENT ( X _ 2 , X _ 1 ) AND HOLD &. THEME ( X _ 2 , OLIVER )\"),\n",
    "\n",
    "    dspy.Example(sentence=\"Hannah burned the valve beside the trunk .\",\n",
    "                 logical_form=\"* FARMER ( X _ 3 ) ; * BEE ( X _ 6 ) ; BURN &. AGENT ( X _ 1 , ARIA ) AND BURN &. THEME ( X _ 1 , X _ 3 ) AND FARMER &. NMOD &. BESIDE ( X _ 3 , X _ 6 )\"),\n",
    "\n",
    "    dspy.Example(sentence=\"A china was eaten by a shoebox .\",\n",
    "                 logical_form=\"JEEP ( X _ 1 ) AND PAINT &. THEME ( X _ 3 , X _ 1 ) AND PAINT &. AGENT ( X _ 3 , X _ 6 ) AND SPEAKER ( X _ 6 )\"),\n",
    "\n",
    "    dspy.Example(sentence=\"Mila liked the newspaper beside the hero .\",\n",
    "                 logical_form=\"* STAND ( X _ 3 ) ; * MOUND ( X _ 6 ) ; LIKE &. AGENT ( X _ 1 , GRAYSON ) AND LIKE &. THEME ( X _ 1 , X _ 3 ) AND STAND &. NMOD &. BESIDE ( X _ 3 , X _ 6 )\"),\n",
    "\n",
    "    dspy.Example(sentence=\"The closet laughed .\",\n",
    "                 logical_form=\"* CRACKER ( X _ 1 ) ; LAUGH &. AGENT ( X _ 2 , X _ 1 )\"),\n",
    "\n",
    "    dspy.Example(sentence=\"Christopher posted the driver on a glacier to William .\",\n",
    "                 logical_form=\"* PILLOW ( X _ 3 ) ; PASS &. AGENT ( X _ 1 , LAYLA ) AND PASS &. THEME ( X _ 1 , X _ 3 ) AND PASS &. RECIPIENT ( X _ 1 , ASHER ) AND PILLOW &. NMOD &. ON ( X _ 3 , X _ 6 ) AND FROG ( X _ 6 )\"),\n",
    "\n",
    "    dspy.Example(sentence=\"Charlie found a futon in a bun .\",\n",
    "                 logical_form=\"FIND &. AGENT ( X _ 1 , GRACE ) AND FIND &. THEME ( X _ 1 , X _ 3 ) AND ROSE ( X _ 3 ) AND ROSE &. NMOD &. IN ( X _ 3 , X _ 6 ) AND BARON ( X _ 6 )\"),\n",
    "\n",
    "    dspy.Example(sentence=\"The knife was collapsed by a trap .\",\n",
    "                 logical_form=\"* FLOWER ( X _ 1 ) ; COLLAPSE &. THEME ( X _ 3 , X _ 1 ) AND COLLAPSE &. AGENT ( X _ 3 , X _ 6 ) AND POOL ( X _ 6 )\")\n",
    "]\n",
    "\n",
    "# Step 3: Create a DSPy module\n",
    "class MetaLearner(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predictor = dspy.Predict(SemanticParsingSignature)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        return self.predictor(sentence=sentence)\n",
    "\n",
    "# Step 4: Instantiate the model and compile with few-shot examples\n",
    "meta_parser = MetaLearner()\n",
    "fewshot_optimizer = LabeledFewShot(k=8)\n",
    "compiled = fewshot_optimizer.compile(student = BasicParse(), trainset=fewshot_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "098aff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Logical Form:\n",
      " DRIVER ( X _ 1 ) AND HELP &. AGENT ( X _ 2 , X _ 1 ) AND HELP &. THEME ( X _ 2 , X _ 3 ) AND SHOEBOX ( X _ 3 )\n"
     ]
    }
   ],
   "source": [
    "query = \"A driver was helped by a shoebox .\"\n",
    "prediction = compiled(sentence=query)\n",
    "print(\"Predicted Logical Form:\\n\", prediction.logical_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36431204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu_please",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
